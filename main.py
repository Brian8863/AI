import os
import cv2
import numpy as np
import threading
import queue
import time
import traceback
import gc
import base64
import copy
import sys
from dataclasses import dataclass, field
from typing import Dict, Optional, Tuple, List

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 

# â˜…â˜…â˜… å¼•å…¥å¿…è¦å¥—ä»¶ â˜…â˜…â˜…
try:
    import requests
    from signalrcore.hub_connection_builder import HubConnectionBuilder
except ImportError:
    print("âŒ éŒ¯èª¤ï¼šè«‹å…ˆå®‰è£å¿…è¦å¥—ä»¶ï¼è¼¸å…¥æŒ‡ä»¤: pip install requests signalrcore")
    sys.exit(1)

from ultralytics import YOLO
try:
    from tensorflow.keras.models import load_model 
    import tensorflow as tf
except ImportError:
    print("è­¦å‘Š: æ‰¾ä¸åˆ° TensorFlowï¼Œå°‡åœç”¨ CNN æ•¸å­—è¾¨è­˜åŠŸèƒ½ã€‚")
    load_model = None

import pyttsx3

# ==========================================
# 1. ç³»çµ±åƒæ•¸é…ç½® (Config)
# ==========================================
@dataclass
class Config:
    # -----------------------------------------------------------
    # [1] å½±åƒè¼¸å…¥ (ESP32 IP)
    # -----------------------------------------------------------
    CAMERA_SOURCE: any = 1  
    
    # -----------------------------------------------------------
    # [2] è‡ªå‹•ç™»å…¥è¨­å®š (ä¾ç…§ç¯„ä¾‹æª”ä¿®æ­£)
    # -----------------------------------------------------------
    LOGIN_URL: str = "https://sbas.runasp.net/api/AccountApi/Login"
    
    # â˜…â˜…â˜… è«‹å¡«å…¥ä½ çš„å¸³è™Ÿå¯†ç¢¼ (ç¨‹å¼æœƒè‡ªå‹•ç™»å…¥æ‹¿ Token) â˜…â˜…â˜…
    USER_EMAIL: str = "TestUser1@gm.chihlee.edu.tw"  # è«‹å¡«å…¥å¯¦éš›å¸³è™Ÿ
    USER_PASSWORD: str = "Aa000000!"   # è«‹å¡«å…¥å¯¦éš›å¯†ç¢¼
    
    # -----------------------------------------------------------
    # [3] SignalR é€£ç·šè¨­å®š (ä¾ç…§ç¯„ä¾‹æª”ä¿®æ­£)
    # -----------------------------------------------------------
    # Hub ç¶²å€
    HUB_URL: str = "https://sbas.runasp.net/chathub"
    
    # â˜…â˜…â˜… é—œéµä¿®æ”¹ 1: å¾Œç«¯æ–¹æ³•åç¨± â˜…â˜…â˜…
    # æ ¹æ“šç¯„ä¾‹æª”ï¼Œå¾Œç«¯æ¥æ”¶çš„æ–¹æ³•å«åš "SendLiveStream"
    HUB_METHOD_NAME: str = "SendLiveStream"
    
    # æ˜¯å¦å•Ÿç”¨å‚³é€åŠŸèƒ½
    ENABLE_STREAMING: bool = True
    
    NEED_ROTATION: bool = False 
    
    # æ¨¡å‹è·¯å¾‘
    MODEL_TRAFFIC: str = "Model/traffic&count.pt" 
    MODEL_ZEBRA: str = "Model/zebra_v3.pt"            
    MODEL_CNN: str = "Model/cnn_digit_model_new.h5" 
    
    # è§£æåº¦èˆ‡æ•ˆèƒ½
    IMGSZ_TRAFFIC: int = 640    
    IMGSZ_ZEBRA: int = 640      
    QUEUE_MAX: int = 1 
    
    # ä¿¡å¿ƒé–€æª»
    CONF_TRAFFIC: float = 0.8    
    CONF_ZEBRA: float = 0.5     
    CONF_CNN: float = 0.7        
    
    # ç¶ è‰²äººè¡Œé“èˆ‡æ–‘é¦¬ç·š
    LOWER_GREEN: np.ndarray = field(default_factory=lambda: np.array([75, 40, 40]))   
    UPPER_GREEN: np.ndarray = field(default_factory=lambda: np.array([92, 255, 255])) 
    ROAD_ROI_TOP: float = 0.5 
    IGNORE_BOTTOM_RATIO: float = 0.1 
    
    # å°èˆªé‚è¼¯
    PATH_DEVIATION_TH: int = 3  
    PATH_CENTER_RATIO: float = 0.15 
    ZEBRA_MIN_AREA: float = 1.5
    
    # èªéŸ³èˆ‡æ™‚é–“
    STARTUP_GRACE_PERIOD: float = 5.0
    PATH_LOST_TIMEOUT: float = 3.0   
    ZEBRA_LOCK_TIMEOUT: float = 2.0 
    REMIND_INTERVAL: float = 5.0 
    TIMEOUT_LOCK: float = 3.0    
    HEARTBEAT_INTERVAL: float = 5.0
    CODE_GREEN: int = 65      
    CODE_RED: int = 67        
    CODE_COUNTDOWN: int = 66  

# ==========================================
# 2. è‡ªå‹•ç™»å…¥æ¨¡çµ„ (Auto Login)
# ==========================================
def get_auth_token(config: Config):
    """
    å‘¼å«å¾Œç«¯ API é€²è¡Œç™»å…¥ï¼Œå–å¾— JWT Token
    """
    print(f"ğŸ”‘ æ­£åœ¨å˜—è©¦ç™»å…¥: {config.LOGIN_URL} ...")
    
    # æ ¹æ“šç¯„ä¾‹æª”ï¼ŒPayload æ¬„ä½ç¢ºèªç‚º Email / Password
    payload = {
        "Email": config.USER_EMAIL,
        "Password": config.USER_PASSWORD
    }
    
    try:
        response = requests.post(config.LOGIN_URL, json=payload, verify=True, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            # æ ¹æ“šç¯„ä¾‹æª”ï¼ŒToken æ”¾åœ¨ "token" æ¬„ä½
            token = data.get("token")
            if token:
                print(f"âœ… ç™»å…¥æˆåŠŸï¼Token (å‰10ç¢¼): {token[:10]}...")
                return token
            else:
                print(f"âŒ ç™»å…¥æˆåŠŸä½†æ‰¾ä¸åˆ° token æ¬„ä½ã€‚å›æ‡‰: {data}")
        else:
            print(f"âŒ ç™»å…¥å¤±æ•— (Status {response.status_code})ï¼š{response.text}")
            
    except Exception as e:
        print(f"âŒ é€£ç·šéŒ¯èª¤ (Login): {e}")
    
    return None

# ==========================================
# 3. èªéŸ³è™•ç†æ¨¡çµ„ (TTS)
# ==========================================
class TTSWorker(threading.Thread):
    def __init__(self):
        super().__init__(daemon=True)
        self.queue = queue.Queue()
        self.stop_event = threading.Event()
        self.engine = None
        self.last_spoken_time = {} 
        self.last_spoken_msg = {} 

    def run(self):
        try:
            self.engine = pyttsx3.init()
            self.engine.setProperty('rate', 140) 
            self.engine.setProperty('volume', 1.0)
            self.engine.startLoop(False)
        except: pass

        while not self.stop_event.is_set():
            try:
                self.engine.iterate() 
                try:
                    msg = self.queue.get_nowait()
                    self.engine.say(msg)
                except queue.Empty: pass
                time.sleep(0.05)
            except: time.sleep(0.1)
        try: self.engine.endLoop()
        except: pass

    def speak(self, msg: str, key: str = "general", interval: float = 0, force: bool = False, clear_queue: bool = False):
        now = time.time()
        last_time = self.last_spoken_time.get(key, 0)
        last_msg = self.last_spoken_msg.get(key, "")
        if force or (msg != last_msg) or (now - last_time > interval):
            if clear_queue:
                with self.queue.mutex: self.queue.queue.clear()
            self.queue.put(msg)
            self.last_spoken_time[key] = now
            self.last_spoken_msg[key] = msg

    def stop(self):
        self.stop_event.set()

# ==========================================
# 4. éåŒæ­¥å½±åƒåµæ¸¬æ¨¡çµ„
# ==========================================
class AsyncTrafficDetector(threading.Thread):
    def __init__(self, config: Config):
        super().__init__(daemon=True)
        self.cfg = config
        self.input_queue = queue.Queue(maxsize=1) 
        self.result_lock = threading.Lock()
        self.running = True
        
        self.latest_results = {
            "traffic": {"green": False, "red": False, "digit": None}, 
            "green_path": {"percentage": 0, "cx": 0, "contours": []},
            "zebra": {"percentage": 0, "cx": 0, "masks_list": [], "box": None},
        }
        self.model_traffic = None; self.model_zebra = None; self.cnn = None

    def update_input(self, frame, cnn_enabled):
        if self.input_queue.full():
            try: self.input_queue.get_nowait()
            except queue.Empty: pass
        self.input_queue.put((frame.copy(), cnn_enabled))

    def get_results(self):
        with self.result_lock: return copy.deepcopy(self.latest_results)

    def run(self):
        print("[AsyncDetector] æ­£åœ¨è¼‰å…¥ AI æ¨¡å‹...")
        self.model_traffic = YOLO(self.cfg.MODEL_TRAFFIC)
        self.model_zebra = YOLO(self.cfg.MODEL_ZEBRA)
        try:
            if load_model: self.cnn = load_model(self.cfg.MODEL_CNN)
        except: self.cnn = None
        print("[AsyncDetector] æ¨¡å‹è¼‰å…¥å®Œæˆ")

        task_counter = 0
        while self.running:
            try:
                frame, cnn_enabled = self.input_queue.get(timeout=0.1)
                traffic_res = self._detect_traffic(frame, cnn_enabled)
                with self.result_lock:
                    current_green = self.latest_results["green_path"]
                    current_zebra = self.latest_results["zebra"]

                if task_counter % 2 == 0:
                    zebra_res = self._detect_zebra(frame)
                    green_res = current_green 
                else:
                    zebra_res = current_zebra 
                    green_res = self._detect_green_path(frame)

                task_counter += 1
                with self.result_lock:
                    self.latest_results["traffic"] = traffic_res
                    self.latest_results["zebra"] = zebra_res
                    self.latest_results["green_path"] = green_res
                time.sleep(0.005)
            except queue.Empty: continue
            except Exception as e: traceback.print_exc()

    def _detect_traffic(self, frame, cnn_enabled):
        res = {"green": False, "red": False, "digit": None}
        try:
            results = self.model_traffic(frame, imgsz=self.cfg.IMGSZ_TRAFFIC, conf=self.cfg.CONF_TRAFFIC, verbose=False)
            for r in results:
                for box, cls in zip(r.boxes.xyxy.cpu().numpy(), r.boxes.cls.cpu().numpy()):
                    c = int(cls); safe_box = [int(x) for x in box]
                    if c == 1: res["green"] = True; res["green_box"] = safe_box
                    elif c == 2: res["red"] = True; res["red_box"] = safe_box
                    elif c == 0: 
                        res["cnt_box"] = safe_box
                        if cnn_enabled and self.cnn:
                            x1,y1,x2,y2 = safe_box
                            h, w = frame.shape[:2]
                            x1, x2 = max(0, x1), min(w, x2)
                            y1, y2 = max(0, y1), min(h, y2)
                            if x2 > x1 and y2 > y1:
                                crop = frame[y1:y2, x1:x2]
                                digit = self._predict_digit(crop)
                                if digit: res["digit"] = digit
        except: pass
        return res

    def _predict_digit(self, img):
        if img.size == 0 or self.cnn is None: return None
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            _, th = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)
            resized = cv2.resize(th, (28, 28)) / 255.0
            input_tensor = resized.reshape(1, 28, 28, 1)
            pred_tensor = self.cnn(input_tensor, training=False)
            pred = pred_tensor.numpy()
            if np.max(pred) > self.cfg.CONF_CNN: return np.argmax(pred)
        except: pass
        return None

    def _detect_green_path(self, frame):
        res = {"percentage": 0, "cx": frame.shape[1]//2, "contours": []}
        h, w = frame.shape[:2]
        try:
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            mask_green = cv2.inRange(hsv, self.cfg.LOWER_GREEN, self.cfg.UPPER_GREEN)
            mask_green[0:int(h * self.cfg.ROAD_ROI_TOP), :] = 0
            if self.cfg.IGNORE_BOTTOM_RATIO > 0:
                mask_green[int(h * (1 - self.cfg.IGNORE_BOTTOM_RATIO)):, :] = 0
            contours, _ = cv2.findContours(mask_green, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                max_cnt = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(max_cnt)
                res["percentage"] = (area / (w * h)) * 100
                M = cv2.moments(max_cnt)
                if M["m00"] != 0: res["cx"] = int(M["m10"] / M["m00"])
                res["contours"] = [c for c in contours if cv2.contourArea(c) > 500]
        except: pass
        return res

    def _detect_zebra(self, frame):
        res = {"percentage": 0, "cx": frame.shape[1]//2, "masks_list": [], "box": None}
        h, w = frame.shape[:2]
        try:
            ai_input = frame.copy()
            if self.cfg.IGNORE_BOTTOM_RATIO > 0:
                ai_input[int(h * (1 - self.cfg.IGNORE_BOTTOM_RATIO)):, :] = 0
            results = self.model_zebra(ai_input, imgsz=self.cfg.IMGSZ_ZEBRA, conf=self.cfg.CONF_ZEBRA, verbose=False, retina_masks=True)
            r = results[0]
            if r.masks is not None:
                all_masks_points = r.masks.xy
                total_area = 0; weighted_cx = 0
                for points in all_masks_points:
                    if len(points) > 0:
                        ys = points[:, 1]
                        if np.min(ys) < h * self.cfg.ROAD_ROI_TOP: continue 
                        pts = points.astype(np.int32)
                        area = cv2.contourArea(pts)
                        if area < 800: continue
                        res["masks_list"].append(pts)
                        total_area += area
                        M = cv2.moments(pts)
                        if M["m00"] != 0: cx = int(M["m10"] / M["m00"]); weighted_cx += cx * area
                if total_area > 0:
                    res["percentage"] = (total_area / (w * h)) * 100
                    res["cx"] = int(weighted_cx / total_area)
            if not res["masks_list"] and r.boxes is not None:
                max_area = 0; best_box = None
                for box in r.boxes.xyxy.cpu().numpy():
                    x1, y1, x2, y2 = map(int, box)
                    if y1 < h * self.cfg.ROAD_ROI_TOP: continue
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area: max_area = area; best_box = (x1, y1, x2, y2)
                if best_box:
                    res["box"] = best_box
                    res["percentage"] = (max_area / (w * h)) * 100
                    res["cx"] = (best_box[0] + best_box[2]) // 2
        except: pass
        return res

# ==========================================
# 5. ç‹€æ…‹ç®¡ç†æ¨¡çµ„
# ==========================================
class TrafficStateManager:
    def __init__(self, config: Config, tts: TTSWorker):
        self.cfg = config; self.tts = tts
        self.lights = {"green": {"state": False, "last_seen": 0, "box": None}, "red": {"state": False, "last_seen": 0, "box": None}}
        self.countdown = {"active": False, "value": 0, "last_tick": 0, "last_digit": None, "box": None}
        self.cnn_enabled = True; self.path_state = "NORMAL"; self.last_path_state = "NORMAL"
        self.last_path_seen_time = time.time(); self.system_start_time = time.time()
        self.last_heartbeat = time.time(); self.prev_light_tts = None
        self.guidance_source = "NONE"; self.smoothed_cx = None; self.last_zebra_time = 0 

    def update(self, det_traffic, det_green, det_zebra, frame_width):
        now = time.time()
        if now - self.last_heartbeat > self.cfg.HEARTBEAT_INTERVAL:
            self.tts.speak("æ»´", key="heartbeat", interval=0, force=True)
            self.last_heartbeat = now
            
        self._update_lights(det_traffic, now)
        self._handle_countdown(det_traffic.get('digit'))
        
        current_light = "red" if self.lights["red"]["state"] else "green" if self.lights["green"]["state"] else None
        if current_light != "red": self._handle_path_guidance(det_green, det_zebra, frame_width, now)
        self._trigger_tts(current_light)

    def _update_lights(self, detections, now):
        current_boxes = {"green": detections.get("green_box"), "red": detections.get("red_box")}
        self.countdown["box"] = detections.get("cnt_box")
        for key in ["green", "red"]:
            detected = detections.get(key, False)
            if detected:
                if not self.lights[key]["state"]:
                    self.lights[key]["state"] = True
                    print(f"SEND SIGNAL: {self.cfg.CODE_GREEN if key=='green' else self.cfg.CODE_RED}")
                self.lights[key]["last_seen"] = now
                self.lights[key]["box"] = current_boxes[key]
            else:
                if self.lights[key]["state"] and (now - self.lights[key]["last_seen"] > self.cfg.TIMEOUT_LOCK):
                    self.lights[key]["state"] = False
                    self.lights[key]["box"] = None
                    if self.prev_light_tts == key: self.prev_light_tts = None

    def _handle_countdown(self, digit):
        if self.countdown["active"]:
            if time.time() - self.countdown["last_tick"] >= 1.0:
                self.countdown["value"] -= 1
                self.countdown["last_tick"] = time.time()
                if self.countdown["value"] <= 0: self.countdown["active"] = False; self.cnn_enabled = True
        if digit is not None and self.countdown.get("last_digit") == 11 and digit == 10:
            self.countdown.update({"active": True, "value": 10, "last_tick": time.time()})
            self.cnn_enabled = False 
            print(f"SEND SIGNAL: {self.cfg.CODE_COUNTDOWN}")
        self.countdown["last_digit"] = digit

    def _handle_path_guidance(self, green_data, zebra_data, width, now):
        zebra_pct = zebra_data.get("percentage", 0); green_pct = green_data.get("percentage", 0)
        center_x = width // 2; new_guidance_source = "NONE"

        if zebra_pct >= self.cfg.ZEBRA_MIN_AREA: 
            new_guidance_source = "ZEBRA"; raw_target_cx = zebra_data.get("cx", center_x); self.last_zebra_time = now 
        elif (now - self.last_zebra_time) < self.cfg.ZEBRA_LOCK_TIMEOUT:
            new_guidance_source = "WAITING_ZEBRA"; raw_target_cx = self.smoothed_cx if self.smoothed_cx else center_x
        elif green_pct >= self.cfg.PATH_DEVIATION_TH:
            new_guidance_source = "GREEN"; raw_target_cx = green_data.get("cx", center_x)
        else:
            new_guidance_source = "NONE"; raw_target_cx = center_x

        self.guidance_source = new_guidance_source
        if new_guidance_source in ["ZEBRA", "GREEN"]:
            if self.smoothed_cx is None: self.smoothed_cx = raw_target_cx
            else: self.smoothed_cx = int(self.smoothed_cx * 0.4 + raw_target_cx * 0.6)
            target_cx = self.smoothed_cx
        elif new_guidance_source == "WAITING_ZEBRA":
             target_cx = self.smoothed_cx if self.smoothed_cx else center_x
        else: target_cx = center_x

        limit_pixel = width * self.cfg.PATH_CENTER_RATIO
        current_state = "NORMAL"; msg = ""

        if new_guidance_source in ["ZEBRA", "GREEN"]:
            self.last_path_seen_time = now
            if target_cx < center_x - limit_pixel: current_state = "SHIFT_LEFT"; msg = "è«‹å‘å·¦ä¿®æ­£"
            elif target_cx > center_x + limit_pixel: current_state = "SHIFT_RIGHT"; msg = "è«‹å‘å³ä¿®æ­£"
        else:
            if now - self.last_path_seen_time > self.cfg.PATH_LOST_TIMEOUT: current_state = "NO_SIGNAL"
            elif now - self.system_start_time < self.cfg.STARTUP_GRACE_PERIOD: current_state = "SEARCHING" 
            else:
                current_state = "OUT_OF_PATH"
                if new_guidance_source != "WAITING_ZEBRA":
                    if self.last_path_state == "NORMAL": msg = ""
                    elif self.last_path_state in ["SHIFT_LEFT", "SHIFT_RIGHT"]: msg = "è­¦å‘Šï¼Œåé›¢è·¯å¾‘"

        self.path_state = current_state 
        state_changed = (current_state != self.last_path_state)
        if msg: self.tts.speak(msg, key="path_guidance", interval=self.cfg.REMIND_INTERVAL, force=state_changed, clear_queue=True)
        self.last_path_state = current_state

    def _trigger_tts(self, current_light):
        if current_light and current_light != self.prev_light_tts:
            if not self.countdown["active"] or self.countdown["value"] > 5:
                msg = "ç´…ç‡ˆè«‹åœä¸‹" if current_light == "red" else "ç¶ ç‡ˆå¯ä»¥èµ°"
                self.tts.speak(msg, key="light", force=True, clear_queue=True)
                self.prev_light_tts = current_light
        if self.countdown["active"] and self.countdown["value"] == 10:
            self.tts.speak("å‰©é¤˜10ç§’", key="cnt_10", force=True, clear_queue=True)

    def get_draw_info(self):
        boxes = []
        for k, v in self.lights.items():
            if v["state"] and v["box"] is not None:
                boxes.append((k.capitalize(), v["box"], (0,255,0) if k=='green' else (0,0,255)))
        if self.countdown["box"] is not None:
            boxes.append(("CNT", self.countdown["box"], (0,255,255)))
        return boxes

# ==========================================
# 6. å½±åƒæ¥æ”¶æ¨¡çµ„ (Input)
# ==========================================
class CameraReceiver(threading.Thread):
    def __init__(self, source, frame_queue):
        super().__init__(daemon=True)
        self.source = source
        self.frame_queue = frame_queue
        self.running = True

    def run(self):
        print(f"ğŸ“· é€£ç·šæ”å½±æ©Ÿ: {self.source}")
        cap = cv2.VideoCapture(self.source)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        if not cap.isOpened():
            print(f"âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ {self.source}")
            return

        print("âœ… å½±åƒä¾†æºå·²é€£ç·š")
        
        while self.running:
            ret, frame = cap.read()
            if not ret:
                print("âš ï¸ è®€å–å¤±æ•—ï¼Œå˜—è©¦é‡é€£...")
                cap.release(); time.sleep(2); cap = cv2.VideoCapture(self.source); continue

            if self.frame_queue.full():
                try: self.frame_queue.get_nowait()
                except: pass
            self.frame_queue.put(frame)
        cap.release()

# ==========================================
# 7. SignalR ç™¼é€å™¨ (ä¿®æ­£ IndentationError ç‰ˆ)
# ==========================================
class SignalRSender(threading.Thread):
    def __init__(self, config: Config, send_queue, token):
        super().__init__(daemon=True)
        self.cfg = config
        self.send_queue = send_queue
        self.token = token
        self.running = True
        self.hub_connection = None
        self.is_connected = False 

    def build_connection(self):
        """å»ºç«‹ä¸€å€‹å…¨æ–°çš„ SignalR é€£ç·šç‰©ä»¶"""
        print(f"ğŸ”„ æ­£åœ¨å»ºç«‹æ–°é€£ç·š: {self.cfg.HUB_URL}")
        token_factory = lambda: self.token
        
        # â˜…â˜…â˜… ä¿®æ­£é»ï¼šä½¿ç”¨å°æ‹¬è™Ÿ () åŒ…è¦†ï¼Œé¿å…æ›è¡ŒéŒ¯èª¤ â˜…â˜…â˜…
        hub = (HubConnectionBuilder()
            .with_url(self.cfg.HUB_URL, options={
                "access_token_factory": token_factory,
                "headers": {"User-Agent": "SmartCane-PC-Client"}
            })
            .configure_logging(logging_level=40) # ä¿®æ­£ï¼šè¨»è§£ç¾åœ¨å®‰å…¨äº†
            .build())
            
        hub.on_open(self.on_open)
        hub.on_close(self.on_close)
        hub.on_error(self.on_error)
        return hub

    def on_open(self):
        print("âœ… SignalR å·²é€£ç·š! é€šé“æš¢é€šã€‚")
        self.is_connected = True

    def on_close(self):
        print("âŒ SignalR å·²æ–·ç·šã€‚")
        self.is_connected = False

    def on_error(self, data):
        print(f"âš ï¸ SignalR ç™¼ç”ŸéŒ¯èª¤: {data}")
        self.is_connected = False

    def run(self):
        print(f"â˜ï¸ å•Ÿå‹• SignalR ç™¼é€åŸ·è¡Œç·’...")
        
        while self.running:
            # 1. ç¢ºä¿é€£ç·šå­˜åœ¨
            if self.hub_connection is None:
                try:
                    self.hub_connection = self.build_connection()
                    self.hub_connection.start()
                    # çµ¦äºˆä¸€é»æ™‚é–“é€²è¡Œæ¡æ‰‹ (Handshake)
                    for _ in range(20): # ç­‰å¾…æœ€å¤š 2 ç§’
                        if self.is_connected: break
                        time.sleep(0.1)
                except Exception as e:
                    print(f"ğŸ”¥ é€£ç·šå»ºç«‹å¤±æ•—: {e}")
                    self.is_connected = False
                    time.sleep(3) # å¤±æ•—å¾Œä¼‘æ¯ 3 ç§’å†è©¦
                    continue

            # 2. å¦‚æœé€£ç·šæˆåŠŸï¼Œé–‹å§‹å‚³é€
            if self.is_connected:
                if not self.send_queue.empty():
                    frame = self.send_queue.get()
                    
                    # é™ä½ç•«è³ªä»¥æ¸›è¼•é »å¯¬å£“åŠ›
                    _, buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 40])
                    jpg_as_text = base64.b64encode(buffer).decode('utf-8')
                    
                    try:
                        self.hub_connection.send(
                            self.cfg.HUB_METHOD_NAME, 
                            [self.cfg.USER_EMAIL, jpg_as_text]
                        )
                    except Exception as e:
                        print(f"âš ï¸ å‚³é€å¤±æ•—: {e}")
                        self.is_connected = False
                        try: self.hub_connection.stop() 
                        except: pass
                        self.hub_connection = None 

                    time.sleep(0.06) 
                else:
                    time.sleep(0.01)
            
            # 3. å¦‚æœæ–·ç·šäº†
            else:
                print("â³ é€£ç·šä¸­æ–·ï¼Œæ­£åœ¨é‡ç½®é€£ç·š...")
                try: 
                    if self.hub_connection: self.hub_connection.stop()
                except: pass
                self.hub_connection = None 
                time.sleep(3) 

        if self.hub_connection:
            self.hub_connection.stop()

# ==========================================
# 8. ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    def emergency_speak(text):
        try:
            eng = pyttsx3.init(); eng.setProperty('rate', 150); eng.say(text); eng.runAndWait()
        except: pass

    try:
        cfg = Config()
        
        # 1. åŸ·è¡Œè‡ªå‹•ç™»å…¥ (å–å¾— Token)
        token = get_auth_token(cfg)
        if not token:
            print("âŒ ç„¡æ³•å–å¾— Tokenï¼Œå°‡ç„¡æ³•å‚³é€å½±åƒåˆ°ç¶²é ï¼")
            # é€™è£¡ä¸å¼·åˆ¶é€€å‡ºï¼Œè®“æœ¬åœ°ç«¯é‚„æ˜¯å¯ä»¥è·‘
        
        tts = TTSWorker(); tts.start()
        
        # AI åµæ¸¬å™¨
        detector = AsyncTrafficDetector(cfg)
        detector.start()
        state_mgr = TrafficStateManager(cfg, tts)
        
        # 2. å•Ÿå‹•è¼¸å…¥
        input_queue = queue.Queue(maxsize=1)
        camera_receiver = CameraReceiver(cfg.CAMERA_SOURCE, input_queue)
        camera_receiver.start()
        
        # 3. å•Ÿå‹• SignalR è¼¸å‡º (å¦‚æœæœ‰ Token)
        output_queue = queue.Queue(maxsize=1)
        if cfg.ENABLE_STREAMING and token:
            streamer = SignalRSender(cfg, output_queue, token)
            streamer.start()

        print(f"ç³»çµ±å•Ÿå‹•ä¸­... è¦–çª—æŒ‰ 'q' å¯é›¢é–‹")
        
        cv2.namedWindow("Smart Guide", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Smart Guide", 1024, 768)
        
        idx = 0
        while True:
            try:
                frame = input_queue.get(timeout=0.1)
            except queue.Empty:
                key = cv2.waitKey(10) & 0xFF
                if key == ord('q'): break
                continue
            
            if cfg.NEED_ROTATION:
                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)

            if idx % 300 == 0: gc.collect()
            idx += 1

            # AI è™•ç†
            detector.update_input(frame, state_mgr.cnn_enabled)
            ai_results = detector.get_results()
            state_mgr.update(ai_results["traffic"], ai_results["green_path"], ai_results["zebra"], frame.shape[1])
            
            # ç•«é¢ç¹ªè£½
            draw_frame = frame.copy()
            try:
                if ai_results["green_path"]["contours"]:
                    cv2.drawContours(draw_frame, ai_results["green_path"]["contours"], -1, (0, 255, 0), 2)
                if ai_results["zebra"].get("masks_list"):
                    overlay = draw_frame.copy()
                    for mask_pts in ai_results["zebra"]["masks_list"]:
                        cv2.fillPoly(overlay, [mask_pts], (0, 165, 255))
                    cv2.addWeighted(overlay, 0.4, draw_frame, 0.6, 0, draw_frame)
                elif ai_results["zebra"].get("box") is not None:
                    bx1, by1, bx2, by2 = ai_results["zebra"]["box"]
                    cv2.rectangle(draw_frame, (bx1, by1), (bx2, by2), (255, 0, 255), 3)

                limit_pixel = int(draw_frame.shape[1] * cfg.PATH_CENTER_RATIO)
                center_x = draw_frame.shape[1] // 2
                cv2.line(draw_frame, (center_x - limit_pixel, 0), (center_x - limit_pixel, draw_frame.shape[0]), (0, 100, 255), 1)
                cv2.line(draw_frame, (center_x + limit_pixel, 0), (center_x + limit_pixel, draw_frame.shape[0]), (0, 100, 255), 1)

                if state_mgr.smoothed_cx is not None and state_mgr.guidance_source != "NONE":
                    cx = state_mgr.smoothed_cx
                    h, w = draw_frame.shape[:2]
                    screen_center_x = w // 2
                    guide_color = (0, 165, 255) if state_mgr.guidance_source == "ZEBRA" else (0, 255, 0)
                    cv2.line(draw_frame, (screen_center_x, h), (cx, h//2), guide_color, 4)
                    cv2.circle(draw_frame, (cx, h//2), 15, guide_color, -1)
                
                roi_y = int(draw_frame.shape[0] * cfg.ROAD_ROI_TOP)
                cv2.line(draw_frame, (0, roi_y), (draw_frame.shape[1], roi_y), (100, 100, 100), 1)

                for label, box, color in state_mgr.get_draw_info():
                    x1,y1,x2,y2 = map(int, box) 
                    x1=max(0,x1); y1=max(0,y1); x2=min(draw_frame.shape[1],x2); y2=min(draw_frame.shape[0],y2)
                    cv2.rectangle(draw_frame, (x1,y1), (x2,y2), color, 3)
                    cv2.putText(draw_frame, label, (x1,y1-10), 0, 0.7, color, 2)
                    
                if state_mgr.countdown["active"]:
                    cv2.putText(draw_frame, f"CNT: {state_mgr.countdown['value']}", (30,80), 0, 2, (0,255,255), 3)
                
                status_text = f"Path: {state_mgr.path_state}"
                if state_mgr.guidance_source != "NONE":
                    status_text += f" [{state_mgr.guidance_source}]"
                cv2.putText(draw_frame, status_text, (30, 40), 0, 0.8, (255,255,0), 2)
            except: pass

            cv2.imshow("Smart Guide", draw_frame)
            
            # â˜…â˜…â˜… å‚³é€çµ¦ SignalR â˜…â˜…â˜…
            if cfg.ENABLE_STREAMING and token and not output_queue.full():
                small_frame = cv2.resize(draw_frame, (640, 480)) 
                output_queue.put(small_frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'): 
                os._exit(0) 

        tts.stop()
        cv2.destroyAllWindows()
    
    except Exception as e:
        print(f"CRASHED: {e}")
        emergency_speak("ç³»çµ±éŒ¯èª¤") 
        os._exit(1)

if __name__ == "__main__":
    main()